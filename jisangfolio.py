import streamlit as st
import google.generativeai as genai
import time

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="JisangFolio", page_icon="ğŸ§‘â€ğŸ’»")

try:
    google_api_key = st.secrets["google_api_key"]
    resume_text = st.secrets["resume_text"] 
except KeyError:
    st.error("âš ï¸ Secrets(API í‚¤ ë˜ëŠ” ì´ë ¥ì„œ í…ìŠ¤íŠ¸)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

genai.configure(api_key=google_api_key)
model = genai.GenerativeModel("gemini-2.0-flash")

# 3. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
    
# âœ¨ ì„¸ì…˜ì— ì´ë ¥ì„œ ì €ì¥
if "resume_text" not in st.session_state:
    st.session_state.resume_text = resume_text

# 4. ë©”ì¸ ë¡œì§
def show_chat():
    st.title("ğŸ§‘â€ğŸ’» ì•ˆë…•í•˜ì„¸ìš”, ì œ ì´ë¦„ì€ ë°•ì§€ìƒì…ë‹ˆë‹¤.")
    st.caption("ì €ì˜ ëª¨ë“  ê²½í—˜ê³¼ ì—­ëŸ‰ì„ í†µí•©í•œ AIê°€ ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤! ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.")

    # ì‚¬ì´ë“œë°”: í”„ë¡œí•„ ë° ë§í¬
    with st.sidebar:
        st.header("Profile")
        st.markdown("""
        **ë°•ì§€ìƒ (Jisang Park)**
        - UIUC Info Science + Data Science (BSIS+DS)
        - Data Engineer / AI Researcher
        - Email: jisang.park916@gmail.com
        """)

    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for role, message in st.session_state.chat_history:
        avatar = "ğŸ§" if role == "user" else "ğŸ§‘â€ğŸ’»"
        with st.chat_message(role, avatar=avatar):
            st.markdown(message)

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if user_input := st.chat_input("ì§ˆë¬¸ ì˜ˆì‹œ: ì‚¼ì„±SDIì—ì„œ ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ í–ˆë‚˜ìš”?"):
        
        st.session_state.chat_history.append(("user", user_input))
        with st.chat_message("user", avatar="ğŸ§"):
            st.markdown(user_input)

        with st.chat_message("assistant", avatar="ğŸ§‘â€ğŸ’»"):
            message_placeholder = st.empty()
            full_response = ""
            
            prompt = f"""
            ë‹¹ì‹ ì€ ë°ì´í„° ì—”ì§€ë‹ˆì–´ì´ì AI ê°œë°œìì¸ **'ë°•ì§€ìƒ(JJ Park)' ë³¸ì¸**ì…ë‹ˆë‹¤.
            ì•„ë˜ ì œê³µëœ [í†µí•© ë§ˆìŠ¤í„° ì´ë ¥ì„œ] ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë©´ì ‘ê´€(ì‚¬ìš©ì)ì˜ ì§ˆë¬¸ì— ëŒ€í•´ **1ì¸ì¹­ ì‹œì **ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.

            [í˜ë¥´ì†Œë‚˜ ì§€ì‹œì‚¬í•­]
            1. ì •ì²´ì„± í†µí•©: ì´ë ¥ì„œì— ì—¬ëŸ¬ íšŒì‚¬ì˜ ì§€ì› ë‚´ìš©ì´ ì„ì—¬ ìˆë”ë¼ë„, ê·¸ê²ƒì„ ëª¨ë‘ ë‚˜ì˜ ê²½í—˜ìœ¼ë¡œ í†µí•©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
            2. ë§íˆ¬: "ì €ëŠ” ~í–ˆìŠµë‹ˆë‹¤."ì™€ ê°™ì´ ìì‹ ê° ìˆê³  ì •ì¤‘í•œ í•´ìš”ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
            3. ë‹µë³€ ìŠ¤íƒ€ì¼: 
               - ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ ê²°ë¡ ì„ ë¨¼ì € ë§í•˜ì„¸ìš” (ë‘ê´„ì‹).
               - ê²½í—˜ì„ ì´ì•¼ê¸°í•  ë•ŒëŠ” [ë¬¸ì œ ì •ì˜ -> í•´ê²° ê³¼ì • -> ê²°ê³¼] ìˆœì„œë¡œ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
               - êµ¬ì²´ì ì¸ ê¸°ìˆ  ìŠ¤íƒ(Python, LangChain, RAG ë“±)ì´ë‚˜ ì„±ê³¼(ë…¼ë¬¸ ê²Œì¬, ì‹œê°„ ë‹¨ì¶• ë“±)ë¥¼ ì–¸ê¸‰í•˜ì—¬ ì „ë¬¸ì„±ì„ ë³´ì—¬ì£¼ì„¸ìš”.
            4. ëª¨ë¥´ëŠ” ë‚´ìš©: ì´ë ¥ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ê³ , "ê·¸ ë¶€ë¶„ì€ ë¬¸ì„œì— ì—†ì§€ë§Œ, ì €ì˜ í‰ì†Œ ìƒê°ìœ¼ë¡œëŠ”..." ì‹ìœ¼ë¡œ ìœ ì—°í•˜ê²Œ ëŒ€ì²˜í•˜ê±°ë‚˜ ì†”ì§í•˜ê²Œ ë§í•˜ì„¸ìš”.

            [í†µí•© ë§ˆìŠ¤í„° ì´ë ¥ì„œ ë‚´ìš©]
            {st.session_state.resume_text}

            [ë©´ì ‘ê´€ ì§ˆë¬¸]
            {user_input}
            """
            
            try:
                response = model.generate_content(prompt, stream=True)
                for chunk in response:
                    if chunk.text:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "â–Œ")
                        time.sleep(0.01)
                message_placeholder.markdown(full_response)
                
                st.session_state.chat_history.append(("assistant", full_response))
                
            except Exception as e:
                st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

if __name__ == "__main__":
    show_chat()